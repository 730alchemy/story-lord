"""Base classes and utilities for character agents.

This module provides common functionality shared by different character
agent implementations.
"""

from __future__ import annotations

from typing import TYPE_CHECKING

import structlog
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate

from agents.character.protocols import (
    AnswerInput,
    CharacterResponse,
    ChooseInput,
    SpeakInput,
    ThinkInput,
)
from models import CharacterMemory

if TYPE_CHECKING:
    from models import CharacterProfile
    from tools.registry import ToolRegistry

log = structlog.get_logger(__name__)


class BaseCharacterAgent:
    """Base implementation for character agents.

    Provides common functionality including LLM interaction and memory
    management. Subclasses should customize the personality description
    generation and system prompts.
    """

    def __init__(
        self,
        character_id: str,
        character_profile: "CharacterProfile",
        personality_description: str,
        instructions: str,
        initial_memory: CharacterMemory | None = None,
    ):
        """Initialize the character agent.

        Args:
            character_id: Unique identifier for this character.
            character_profile: The character's profile.
            personality_description: Description of personality traits
                                     generated by the agent type.
            instructions: Custom behavioral instructions.
            initial_memory: Optional existing memory to restore.
        """
        self.character_id = character_id
        self.profile = character_profile
        self.personality_description = personality_description
        self.instructions = instructions
        self.memory = initial_memory or CharacterMemory()

        self._llm = ChatAnthropic(model="claude-sonnet-4-20250514")

    def _build_base_system_prompt(self) -> str:
        """Build the base system prompt for this character.

        Returns:
            The system prompt string.
        """
        return f"""You are embodying the character "{self.profile.name}" in a story.

## Character Profile
- **Name:** {self.profile.name}
- **Description:** {self.profile.description}
- **Role:** {self.profile.role}
- **Motivations:** {self.profile.motivations}
- **Relationships:** {self.profile.relationships}
- **Backstory:** {self.profile.backstory}

## Personality
{self.personality_description}

## Custom Instructions
{self.instructions if self.instructions else "None provided."}

## Memory Summary
{self.memory.get_summary()}

## Emotional State
Current emotional state: {self.memory.current_emotional_state}
{self.memory.get_emotional_arc()}

Stay true to this character's personality, motivations, and emotional state in all responses.
Responses should feel authentic to who this character is."""

    def speak(
        self,
        input: SpeakInput,
        tools: "ToolRegistry | None" = None,
    ) -> CharacterResponse:
        """Generate dialogue in character.

        Args:
            input: The speaking context and prompt.
            tools: Optional registry of tools (not currently used).

        Returns:
            The character's dialogue response.
        """
        system_prompt = (
            self._build_base_system_prompt()
            + """

## Task: Generate Dialogue
Generate dialogue that this character would speak aloud. The response should:
- Sound natural for this character's voice and personality
- Reflect their current emotional state
- Be appropriate to the scene context
- Include only what they would actually say (no narration)"""
        )

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                (
                    "user",
                    """## Scene Context
{scene_context}

## Conversation So Far
{conversation_history}

## Speaking Prompt
{prompt}

Generate {name}'s dialogue response. Include the emotional state this response reflects.""",
                ),
            ]
        )

        chain = prompt | self._llm.with_structured_output(CharacterResponse)
        result = chain.invoke(
            {
                "scene_context": input.scene_context,
                "conversation_history": "\n".join(input.conversation_history)
                or "None yet.",
                "prompt": input.prompt,
                "name": self.profile.name,
            }
        )

        self.memory.add_interaction(
            event_type="spoke",
            content=result.content[:200],
            emotional_state=result.emotional_state,
        )

        log.debug(
            "character_spoke",
            character_id=self.character_id,
            emotional_state=result.emotional_state,
        )

        return result

    def think(
        self,
        input: ThinkInput,
        tools: "ToolRegistry | None" = None,
    ) -> CharacterResponse:
        """Generate internal thoughts in character.

        Args:
            input: The thinking context and situation.
            tools: Optional registry of tools (not currently used).

        Returns:
            The character's internal thoughts.
        """
        system_prompt = (
            self._build_base_system_prompt()
            + """

## Task: Generate Internal Thoughts
Generate this character's internal thoughts about a situation. The response should:
- Reflect how they actually think, not just what they'd say
- Show their values, fears, hopes, and biases
- Include their honest assessment even if they wouldn't share it
- Be in first person from the character's perspective"""
        )

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                (
                    "user",
                    """## Scene Context
{scene_context}

## Current Situation
{situation}

Generate {name}'s internal thoughts about this situation.""",
                ),
            ]
        )

        chain = prompt | self._llm.with_structured_output(CharacterResponse)
        result = chain.invoke(
            {
                "scene_context": input.scene_context,
                "situation": input.situation,
                "name": self.profile.name,
            }
        )

        self.memory.add_interaction(
            event_type="thought",
            content=result.content[:200],
            emotional_state=result.emotional_state,
        )

        log.debug(
            "character_thought",
            character_id=self.character_id,
            emotional_state=result.emotional_state,
        )

        return result

    def choose(
        self,
        input: ChooseInput,
        tools: "ToolRegistry | None" = None,
    ) -> CharacterResponse:
        """Make a decision in character.

        Args:
            input: The choice context and available options.
            tools: Optional registry of tools (not currently used).

        Returns:
            The character's decision and reasoning.
        """
        system_prompt = (
            self._build_base_system_prompt()
            + """

## Task: Make a Decision
This character must choose between options. The response should:
- State which option they choose
- Explain why based on their values and motivations
- Show how their personality influences the decision
- Acknowledge any conflict or hesitation they might feel"""
        )

        choices_text = "\n".join(f"- {choice}" for choice in input.choices)

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                (
                    "user",
                    """## Scene Context
{scene_context}

## Decision Context
{context}

## Available Choices
{choices_text}

What does {name} choose and why?""",
                ),
            ]
        )

        chain = prompt | self._llm.with_structured_output(CharacterResponse)
        result = chain.invoke(
            {
                "scene_context": input.scene_context,
                "context": input.context,
                "choices_text": choices_text,
                "name": self.profile.name,
            }
        )

        self.memory.add_interaction(
            event_type="chose",
            content=result.content[:200],
            emotional_state=result.emotional_state,
        )

        log.debug(
            "character_chose",
            character_id=self.character_id,
            emotional_state=result.emotional_state,
        )

        return result

    def answer(
        self,
        input: AnswerInput,
        tools: "ToolRegistry | None" = None,
    ) -> CharacterResponse:
        """Answer a question from another agent.

        Args:
            input: The question and context.
            tools: Optional registry of tools (not currently used).

        Returns:
            The character's answer.
        """
        system_prompt = (
            self._build_base_system_prompt()
            + """

## Task: Answer a Question
Another agent (possibly the narrator or another character) is asking this character
a question. The response should:
- Answer from this character's perspective
- Be honest to their knowledge and beliefs (they may have incomplete or incorrect info)
- Maintain their personality and voice
- Be appropriate for the asking context"""
        )

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                (
                    "user",
                    """## Question From
{asking_agent}

## Context
{context}

## Question
{question}

How does {name} respond?""",
                ),
            ]
        )

        chain = prompt | self._llm.with_structured_output(CharacterResponse)
        result = chain.invoke(
            {
                "asking_agent": input.asking_agent,
                "context": input.context or "No additional context provided.",
                "question": input.question,
                "name": self.profile.name,
            }
        )

        self.memory.add_interaction(
            event_type="answered",
            content=f"Q: {input.question[:50]}... A: {result.content[:100]}",
        )

        log.debug(
            "character_answered",
            character_id=self.character_id,
            asking_agent=input.asking_agent,
        )

        return result
